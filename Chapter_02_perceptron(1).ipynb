{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "## The perceptron\n",
    "\n",
    "\n",
    "    Hand-in bug-free (try \"Kernel\" > \"Restart & Run All\") and including all (textual as well as figural) output via Blackboard before the deadline (see Blackboard).\n",
    "    \n",
    "Learning goals:\n",
    "1. Implement a perceptron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: The activation function (1 point)\n",
    "The perceptron uses the *linear threshold activation* function $g(\\mathbf{x})$ with $\\theta=0$. Write a function ```linear_threshold(x, theta)``` that computes this activation given any input $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_treshold(x,theta=0):\n",
    "    if x>=theta:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_treshold(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Perceptron output (1 point)\n",
    "The output $y$ of a perceptron is given by $y=g(\\mathbf{w}^\\top \\mathbf{x})$, with input vector $\\mathbf{x}$, the weight vector $\\mathbf{w}$, and the activation function $g$. Write a function ```compute_output(x,w)``` that computes the output of a perceptron, given a single pattern $\\mathbf{x}$ and the current perceptron weights $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_output(x,w):\n",
    "    activation_input=np.dot(x,w)\n",
    "    return linear_treshold(activation_input)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inputs = np.array([4.0,2.0,3.0])\n",
    "weights  = np.array([-0.7,-0.3,-0.2])\n",
    "compute_output(x_inputs,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Weight update (1 point)\n",
    "A perceptron is trained (i.e. it learns the right weights) following the perceptron convergence procedure. Write a function ```update_weights(w, x, y, t)``` that performs this procedure. Specifically, write a function that returns the updated perceptron weights following the rule from the lecture, given one input pattern $\\mathbf{x}$, its target output $\\mathbf{t}$, the current set of weights $\\mathbf{w}$ and the (already calculated) output of the perceptron $\\mathbf{y}$. \n",
    "\n",
    "You don't need to calculate the perceptron output $\\mathbf{y}$ here, it will be calculated in the final perceptron training function with your ```compute_output()``` function. \n",
    "\n",
    "Hint: This is a very short function again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(w,x,y,t):\n",
    "    updated_weights=[]\n",
    "    if y==1 and t==0:\n",
    "        updated_weights=[z - y for z, y in zip(w, x)]\n",
    "        \n",
    "    elif y==0 and t==1:\n",
    "        updated_weights=[z + y for z, y in zip(w, x)]\n",
    "    \n",
    "    else:\n",
    "        updated_weights=list(w)\n",
    "        \n",
    "    return updated_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Training (1.5 points)\n",
    "You now have implemented all the building blocks for a perceptron. Now, write a function ```perceptron_train(X, T, num_epochs)``` that trains and returns weights $\\mathbf{w}$ for a perceptron, given a dataset $\\mathbf{X}$ and targets $\\mathbf{T}$.\n",
    "\n",
    "`n` is the number of training examples. `m` is the number of weights. Expect $\\mathbf{X}$ to be a matrix containing the training examples with dimensions `(m,n)` and $\\mathbf{T}$ containing the targets for each example, a vector with length `n`.\n",
    "\n",
    "It should train for 10 epochs (iterations over all training examples). Make use of `np.random.permutation` to avoid that you are always iterating over the examples in the same order. \n",
    "\n",
    "For now only implement ```perceptron_train(X, T, num_epochs)```. We will call and test it later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptron_train(X, T, num_epochs=10):\n",
    "    m, n = X.shape\n",
    "    print(m,n)\n",
    "    # Initialize the right number of weights as zeros\n",
    "    w=np.zeros(m)\n",
    "    # Loop over epochs\n",
    "    for i in range(0,num_epochs):\n",
    "        # Loop over all examples in random order\n",
    "        for index in range(0,n):\n",
    "            # Take an example\n",
    "\n",
    "            x=X[0:m,index]\n",
    "\n",
    "            # Compute the output of the perceptron\n",
    "            y=compute_output(x,w)\n",
    "            # Update the weights of the perceptron\n",
    "            \n",
    "            w=update_weights(w,x,y,T[index])\n",
    "            \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Testing (1.5 points)\n",
    "In addition to the training function, write a function `perceptron_test(X,w)` that computes and returns the outputs $\\mathbf{Y}$ for a given dataset $\\mathbf{X}$ and a perceptron given by its weights $\\mathbf{w}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptron_test(X, w):\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # Create an output array Y that you use to store the perceptron outputs\n",
    "    Y=[]\n",
    "    # Loop over the examples\n",
    "    for index in range(0,n):\n",
    "        # Take an example\n",
    "        x=X[0:n,index]\n",
    "        # Compute the output of the perceptron\n",
    "        Y.append(compute_output(x,w))\n",
    "        \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: OR (1 point)\n",
    "Use your functions to train and test a perceptron on the OR problem, given by input patterns $\\mathbf{X}$ and targets $\\mathbf{T}$. \n",
    "\n",
    "Print your trained perceptron's outputs $\\mathbf{Y}$ and the expected outputs $\\mathbf{T}$ for the OR problem  to check whether your perceptron has learned successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]], dtype=\"float32\").T\n",
    "\n",
    "# Targets\n",
    "T = np.array([0, 1, 1, 1], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2L, 4L)\n"
     ]
    }
   ],
   "source": [
    "w=perceptron_train(X, T, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=perceptron_test(X, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x98c9cc0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEXCAYAAABlI9noAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqRmDBVJUjP/H/6YbF9/nOaHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x97e8a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot data\n",
    "plt.figure()\n",
    "for i_example in range(X.shape[1]):\n",
    "    if T[i_example] == 1:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"or\")\n",
    "    else:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"ob\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.title(\"OR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add bias terms\n",
    "X = np.vstack((np.ones((1, X.shape[1])), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the perceptron\n",
    "\n",
    "# Apply the perceptron\n",
    "\n",
    "# Print predictions and targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: AND (1 point)\n",
    "Train and test your perceptron on the AND problem, given by input patterns $\\mathbf{X}$ and targets $\\mathbf{T}$. \n",
    "\n",
    "Print your trained perceptron's outputs $\\mathbf{Y}$ and the expected outputs for the AND problem $\\mathbf{T}$ to check whether your perceptron has learned successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]], dtype=\"float32\").T\n",
    "\n",
    "# Targets\n",
    "T = np.array([0, 0, 0, 1], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.figure()\n",
    "for i_example in range(X.shape[1]):\n",
    "    if T[i_example] == 1:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"or\")\n",
    "    else:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"ob\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.title(\"AND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add bias terms\n",
    "X = np.vstack((np.ones((1, X.shape[1])), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the perceptron\n",
    "\n",
    "# Apply the perceptron\n",
    "\n",
    "# Print predictions and targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: XOR (1 point)\n",
    "Train and test your perceptron on the XOR problem, given by input patterns $\\mathbf{X}$ and targets $\\mathbf{T}$. \n",
    "\n",
    "Print your trained perceptron's outputs $\\mathbf{Y}$ and the expected outputs for the XOR problem $\\mathbf{T}$ to check whether your perceptron has learned successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]], dtype=\"float32\").T\n",
    "\n",
    "# Targets\n",
    "T = np.array([0, 1, 1, 0], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.figure()\n",
    "for i_example in range(X.shape[1]):\n",
    "    if T[i_example] == 1:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"or\")\n",
    "    else:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"ob\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.title(\"XOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add bias terms\n",
    "X = np.vstack((np.ones((1, X.shape[1])), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the perceptron\n",
    "\n",
    "# Apply the perceptron\n",
    "\n",
    "# Print predictions and targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: Interpretation (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which of the three problems OR, AND and XOR did the perceptron learn, and which did it not learn?\n",
    "1. Which property do the patterns in $\\mathbf{X}$ need to have so that the perceptron can learn them? \n",
    "1. Which of the three problems do or do not have this property?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write your answer here.\n",
    "1. Write your answer here.\n",
    "1. Write your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
